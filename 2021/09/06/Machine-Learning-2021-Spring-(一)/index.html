<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/128x128.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/16x16.png">
  <link rel="mask-icon" href="/images/star.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="记录一些关于学习B站李宏毅老师的机器学习视频的笔记  Day1">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning 2021 Spring (一)">
<meta property="og:url" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/index.html">
<meta property="og:site_name" content="xinkjung&#39;s Blog">
<meta property="og:description" content="记录一些关于学习B站李宏毅老师的机器学习视频的笔记  Day1">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/1.LinearModels.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/2.sigmoid.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/3.redcurve.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/4.sigmoid_1.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/5.sigmoid_2.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/6.sigmoid_3.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/7.sigmoid_4.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/8.sigmoid_5.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/9.newmodel.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/10.newmodel_loss.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/11.optimization_of_newmodel.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/12.Example.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/13.ReLU.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/14.ActivationFunction.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/15.Hyperparameters.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/16.NeutralNetwork.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/17.DeepLearning.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/18.Overfitting.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/19.FullyConnectFeedforwardNetwork_example1.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/20.FullyConnectFeedforwardNetwork_example2.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/21.FullyConnectFeedforwardNetwork.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/22.MatrixOperation_1.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/23.MatrixOperation_2.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/24.CrossEntropy.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/25.TotalLoss.png">
<meta property="og:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/26.GradientDescent.png">
<meta property="article:published_time" content="2021-09-06T12:14:13.000Z">
<meta property="article:modified_time" content="2021-09-13T08:36:01.152Z">
<meta property="article:author" content="xxx">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/1.LinearModels.png">

<link rel="canonical" href="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Machine Learning 2021 Spring (一) | xinkjung's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">xinkjung's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-commonweal">

    <a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/xin.jpg">
      <meta itemprop="name" content="xxx">
      <meta itemprop="description" content=" Be happy. ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="xinkjung's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Machine Learning 2021 Spring (一)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-06 20:14:13。" itemprop="dateCreated datePublished" datetime="2021-09-06T20:14:13+08:00">2021-09-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-09-13 16:36:01。" itemprop="dateModified" datetime="2021-09-13T16:36:01+08:00">2021-09-13</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">记录一些关于学习B站李宏毅老师的机器学习视频的笔记  Day1</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="一、机器学习基本概念"><a href="#一、机器学习基本概念" class="headerlink" title="一、机器学习基本概念"></a>一、机器学习基本概念</h2><blockquote class="blockquote-center">
            <i class="fa fa-quote-left"></i>
            <p>Machine Learning  $\approx$  Looking for Function</p>

            <i class="fa fa-quote-right"></i>
          </blockquote>

<p>机器学习就是让机器具备找一个函数式的能力，即一种实现人工智能的方法</p>
<h3 id="Different-types-of-Functions"><a href="#Different-types-of-Functions" class="headerlink" title="Different types of Functions"></a>Different types of Functions</h3><p><strong><u>Regression</u></strong>: outputs a scalar.  它的输出是一个数值。</p>
<p><strong><u>Classification</u></strong>: outputs the correct one from given options(classes).  从设定好的选项里面选择一个当作输出。</p>
<p><strong><u>Structured Learning</u></strong>: create something with structure(image, document).   机器学会创造这件事。</p>
<h3 id="Linear-Models-之机器学习找函数式的过程-——-三个步骤"><a href="#Linear-Models-之机器学习找函数式的过程-——-三个步骤" class="headerlink" title="Linear Models 之机器学习找函数式的过程 —— 三个步骤"></a>Linear Models 之机器学习找函数式的过程 —— 三个步骤</h3><blockquote>
<ol>
<li>Function with Unknown Parameters</li>
</ol>
</blockquote>
<p>写出一个带有未知参数的函数式F， <strong>Model</strong>  $y = b + wx_1$ </p>
<ul>
<li>$y$ : Model, no. of views on 2/26</li>
<li>$x_1$ : feature, no. of views on 2/25</li>
<li>$w$ : weight, unkown parameters(learned from data)</li>
<li>$b$ : bias, unkown parameters(learned from data)</li>
</ul>
<blockquote>
<ol start="2">
<li>Define Loss from Traning Data</li>
</ol>
</blockquote>
<p>定义一个loss函数，输入是Model里面的参数 </p>
<p><i class="fa fa-arrow-circle-right"></i> Loss is a function of parameters  $L(b, w)$</p>
<p><i class="fa fa-arrow-circle-right"></i> Loss means how good a set of values is.  当未知参数被设定时，评估输出的这笔数值好还是不好</p>
<p>对每一次的预测估计都有 $e = \mid y - \widehat{y} \mid$<br>最后计算得到结果 <strong>Loss</strong>  $L = \frac{1}{N} \sum_{i=1}^{n}{e_n} $</p>
<ul>
<li>$\widehat{y}$ : label, 真实的值（正确的数值）</li>
<li>$e_i$ : 每次估测的值与正确的值之间的差距（有不同的计算方法）</li>
<li>$N$ : 训练资料的总个数</li>
<li>$L$ : 每一笔训练资料的误差，L越大代表这组参数越不好，L越小代表现在这组参数越好</li>
</ul>
<p>采用哪种方法来衡量距离e根据个人需求和对任务的理解来进行选择，这里选择<code>MAE</code></p>
<p>$\bullet$  $e = \mid y - \widehat{y} \mid$    , L is mean absolute error(MAE)</p>
<p>$\bullet$  $e = (y - \widehat{y})^2$          , L is mean square error(MSE)</p>
<span class="label info">如果 $y$ 和 $\widehat{y}$ 都是几率分布的话可能会选择 `Cross- entropy`</span>

<p>尝试不同的参数来计算各参数对应Loss而画出一个图叫 <code>Error Surface</code> （可以是1D或2D，即一个或两个参数可变）</p>
<blockquote>
<ol start="3">
<li>Optimization</li>
</ol>
</blockquote>
<p>解决一个最佳化的问题，找到最佳的w和b使得loss最小 </p>
<p>$$w^*, b^* = arg\ min_{w,b}\ L $$</p>
<p><strong><u>Gradient Descent</u></strong>  <span class="label primary">（一个参数的情况）</span></p>
<p><i class="fa fa-chevron-right"></i> (Randomly) Pick an initial value $w^0$</p>
<p><i class="fa fa-chevron-right"></i> Compute $\frac{\partial{L}}{\partial{w}}\vert_{w=w^0}$ ,<br>计算在$w=w^0$的时候w这个参数对Loss的微分是多少，即在error surface这一个点的切线斜率</p>
<ul>
<li>Negative $\Rightarrow$ Increase w , 斜率为负数则增大w，就可以使loss的值变小</li>
<li>Positive $\Rightarrow$ Decrease w , 斜率为正数则减小w，可以让loss的值变小</li>
</ul>
<p>$$w^1 - w^0 = \eta * \frac{\partial{L}}{\partial{w}}|_{w=w^0}$$</p>
<p><i class="fa fa-chevron-right"></i> Update $w$ iteratively</p>
<ul>
<li>$\eta$ : learnign rate, 学习速率（自己设定，值大学习快），当微分值为0时就不再更新参数</li>
<li>hyperparameters: 机器学习中需要自己设定的参数    </li>
</ul>
<span class="label warning">这个方法可能存在local minima并不是我们想要的global minima的问题</span>

<p><strong><u>Gradient Descent</u></strong>  <span class="label primary">（两个参数的情况）</span></p>
<p><i class="fa fa-chevron-right"></i> (Randomly) Pick an initial value $w^0$, $b^0$</p>
<p><i class="fa fa-chevron-right"></i> Compute<br>$\eta \frac{\partial{L}}{\partial{w}} \vert_{w=w^0,b=b^0}$ ,<br>$\eta \frac{\partial{L}}{\partial{b}} \vert_{w=w^0,b=b^0}$ ,<br>计算在$w=w^0,\ b=b^0$的位置w这个参数对Loss的微分是多少以及在$w=w^0,\ b=b^0$的位置w这个参数对Loss的微分是多少</p>
<p><i class="fa fa-chevron-right"></i> Update $w$ and $b$ iteratively</p>
<p>$$w^1 =  w^0 - \eta \frac{\partial{L}}{\partial{w}}|_{w=w^0,b=b^0}$$</p>
<p>$$b^1 =  b^0 - \eta \frac{\partial{L}}{\partial{b}}|_{w=w^0,b=b^0}$$</p>
<div class="note info">
            <p>机器学习找函数式的以上三个步骤合起来称为 <em><strong><u>Training</u></strong></em> </p>
          </div>

<p>也就是说用旧的一些真实的数据训练的模型来预测之后可能的模型结果。</p>
<span class="label info">通常一个模型的修改往往来自于对这个模型的理解，也就是`Domain Knowledg`</span>

<p>观察我们随便乱写得到的真实模型发现每7天一个周期循环，所以写一个新模型 $y = b + \sum_{j=1}^7 w_jx_j$ ，发现sum求和数量依次增多后会达到一个饱和，误差率不再减小</p>
<div class="note info">
            <p>feature <code>x</code> * weight <code>w</code> + bias <code>b</code> 模型称作  <em><strong><u>Linear models</u></strong></em> </p>
          </div>

<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/1.LinearModels.png" alt="Linear Models"></p>
<h3 id="New-Model-More-Features"><a href="#New-Model-More-Features" class="headerlink" title="New Model : More Features"></a>New Model : More Features</h3><p>但是linear models过于简单且有一定的限制，这个东西叫做 <em><strong>Model Bias</strong></em> ，由此产生了一个更复杂且含有未知参数的function</p>
<p>All Piecewise Linear Curves = constant + sum of a set</p>
<blockquote>
<p>Sigmoid Function —— S型曲线</p>
</blockquote>
<p>曲折的直线函数可以看作一条曲线，而实际上sigmoid function 就是一个S型的曲线，它可以由一个函数式来表示</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/2.sigmoid.png" alt="Sigmoid Function"></p>
<p>$$<br>\begin{align}<br>y &amp; = c \ \frac{1}{1+e^{-(b+wx_1)}}  \<br>&amp; = c \ sigmoid \ (b+wx_1) \<br>\end{align}<br>$$</p>
<p>曲折的直线函数也可以由一个常量和一些线段的集合来表示</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/3.redcurve.png" alt="Sigmoid Function - sum of a set + constant"></p>
<p>$$<br>\begin{align}<br>y &amp; = b + \sum_j w_jx_j  \<br>y &amp; = b + \sum_i c_i \ sigmoid \ (b_i + \sum_j w_{i,j}x_j)  \<br>\end{align}<br>$$</p>
<p>其实函数式只有一些细微的差别，下面深入解析一下这个sigmoid function</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/4.sigmoid_1.png" alt="sigmoid 解析"></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/5.sigmoid_2.png" alt="sigmoid 解析"></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/6.sigmoid_3.png" alt="sigmoid 解析"></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/7.sigmoid_4.png" alt="sigmoid 解析"></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/8.sigmoid_5.png" alt="sigmoid 解析"></p>
<h3 id="Back-to-ML-Framework"><a href="#Back-to-ML-Framework" class="headerlink" title="Back to ML Framework"></a>Back to ML Framework</h3><blockquote>
<p>Step 1: function with unknown</p>
</blockquote>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/9.newmodel.png" alt="function with unknown"></p>
<blockquote>
<p>Step 2: define loss from traning data</p>
</blockquote>
<p><i class="fa fa-arrow-circle-right"></i> Loss is a function of parameters  $L(\theta)$</p>
<p><i class="fa fa-arrow-circle-right"></i> Loss means how good a set of values is. </p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/10.newmodel_loss.png" alt="Loss"></p>
<p>得到结果 <strong>Loss</strong>  $L = \frac{1}{N} \sum_ne_n $</p>
<blockquote>
<p>Step 3: optimization</p>
</blockquote>
<p>$$<br>\begin{align}<br>\theta &amp;=<br>    \begin{bmatrix}<br>        \theta_1 \<br>        \theta_2 \<br>        \theta_3 \<br>         \vdots  \<br>    \end{bmatrix}<br>\end{align}<br>$$</p>
<p>$$\theta^* = arg\ min_\theta\ L $$</p>
<p><i class="fa fa-chevron-right"></i> (Randomly) Pick an initial value $\theta^0$</p>
<p><i class="fa fa-chevron-right"></i> Compute $ g =  \nabla L (\theta^0) $</p>
<p>$$<br>g_{gradient} = \begin{bmatrix}<br>                \frac{\partial L} {\partial \theta_1} |<em>{\theta = \theta^0} \<br>                \frac{\partial L} {\partial \theta_2} |</em>{\theta = \theta^0} \<br>                \vdots<br>               \end{bmatrix} \</p>
<p>$$</p>
<p>计算所有参数 $\theta^1、\theta^2、\theta^3$ 在 $\theta^0$ 的位置对 $L$ 的微分作为Gradient 向量。</p>
<p>$$<br>\begin{bmatrix}<br>    \theta_1^1 \<br>    \theta_2^1 \<br>      \vdots   \<br>\end{bmatrix}<br> =<br>\begin{bmatrix}<br>    \theta_1^0 \<br>    \theta_2^0 \<br>      \vdots   \<br>\end{bmatrix}<br> -<br>\begin{bmatrix}<br>    \eta  \frac{\partial{L}}{\partial{\theta_1}}|<em>{\theta=\theta^0} \<br>    \eta  \frac{\partial{L}}{\partial{\theta_2}}|</em>{\theta=\theta^0} \<br>      \vdots   \<br>\end{bmatrix}<br>$$</p>
<p><strong>Update</strong>  $ \theta^1 \leftarrow \theta^0 - \eta g $</p>
<p><i class="fa fa-chevron-right"></i> Compute $ g =  \nabla L (\theta^1) $</p>
<p><strong>Update</strong> $ \theta^2 \leftarrow \theta^1 - \eta g $</p>
<p><i class="fa fa-chevron-right"></i> Compute $ g =  \nabla L (\theta^2) $</p>
<p><strong>Update</strong> $ \theta^3 \leftarrow \theta^2 - \eta g $</p>
<p>以此类推，通常做到不想做之后停下来</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/11.optimization_of_newmodel.png" alt="optimization"></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/12.Example.png" alt="Example"></p>
<h3 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h3><blockquote>
<p>Sigmoid ➡️ ReLU （Rectified Linear Unit ）</p>
</blockquote>
<p>除了sigmoid ，也可以使用<code>ReLU</code>函数</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/13.ReLU.png" alt="Sigmoid-ReLU"></p>
<p>$$<br>y  = b + \sum_{2i} c_i \ max \ (0, b_i + \sum_j w_{i,j}x_j)<br>$$</p>
<blockquote>
<p> Activation function</p>
</blockquote>
<p>我们称 sigmoid 和 max 为 <code>Activation function</code></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/14.ActivationFunction.png" alt="Activation function"></p>
<blockquote>
<p>Hyperparameters</p>
</blockquote>
<p>这些生成的可控的参数就称之为<code>Hyperparameters</code></p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/15.Hyperparameters.png" alt="Hyperparameters"></p>
<blockquote>
<p>Neutral Network</p>
</blockquote>
<p>我们将激活函数称为Neuron神经元，复合而成就生称了<code>Neutral Network</code>神经网络</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/16.NeutralNetwork.png" alt="Neutral Network"></p>
<blockquote>
<p>Deep Learning</p>
</blockquote>
<p>每一层神经元就称为hidden layer隐藏层，由很多层组成的神经网络我们叫它<code>Deep Learning</code>深度学习</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/17.DeepLearning.png" alt="Deep Learning"></p>
<blockquote>
<p>Overfitting</p>
</blockquote>
<p>但有时候使用更多的层数并没有更好的效率，训练集准确率高了但实际预测数据集准确率很低，这是因为达到了<code>Overfitting</code>过拟合。</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/18.Overfitting.png" alt="Overfitting"></p>
<h3 id="To-Learn-More-Three-Steps-for-Deep-Learning"><a href="#To-Learn-More-Three-Steps-for-Deep-Learning" class="headerlink" title="To Learn More - Three Steps for Deep Learning"></a>To Learn More - Three Steps for Deep Learning</h3><blockquote>
<p>Step 1: define a set of function</p>
</blockquote>
<p>这个function其实就是Neural Network，然后将这些Neural Network用不同的方式连接起来，比如<code>Fully Connect Feedforward Network</code>，就是将前一层和后一层的每个神经元都互相连接起来。</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/19.FullyConnectFeedforwardNetwork_example1.png" alt="Example 1 - Fully Connect Feedforward Network"></p>
<p>对于每条线和每个点，我们给它们添加上weight和bias的值，然后带入公式 $y=b+wx$ 计算，再通过sigmoid function的结果就是输出。</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/20.FullyConnectFeedforwardNetwork_example2.png" alt="Example 1 - Fully Connect Feedforward Network"></p>
<p>通常来讲，我们会有很多排neuron，每一排neuron里面可能会有很多个neuron，在layer和layer之间的neuron，是两两互相连接的，layer1的neuron的output就是所有layer2的neuron<br>的input，layer2的neuron的nput就是所有layer1的output。整个Network需要一个input，这个input就是一个vector， 对layer1的每一个neuron来说，它的input就是input layer的每一个dimension。最后假设第L排有M个neuron的话，这M个layer L的输出就是最后的output，组成一个vector。</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/21.FullyConnectFeedforwardNetwork.png" alt="Fully Connect Feedforward Network"></p>
<span class="label info"> Deep = Many hidden layers</span>

<p>Network的运作我们常常会用<code>Matrix Operation</code>来表示</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/22.MatrixOperation_1.png" alt="Matrix Operation"></p>
<p>对于一整个neural network，我们也可以使用<code>Matrix Operation</code>这样表示</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/23.MatrixOperation_2.png" alt="Matrix Operation"></p>
<p>比如手写数字识别，对于一个neural network我们也可以将最后一层output当作一个<code>multiclass classifier</code>，然后对其添加softMax，最后输出就是每一个数字的概率。</p>
<blockquote>
<p>Step 2: goodness of function</p>
</blockquote>
<p>假设给定了一组参数，要做手写数字辨识，我有一张image跟它的label，于是现在的target就是一个10维的vector，只有在第一纬对应到数字1的地方它的值为1，其他都是0。将image的pixel输入，得到一组输出y，然后计算 $y$ 跟 $\widehat y$ 之间的 <code>cross entropy</code> ，接下来就是要调整network的参数使得这个 cross entropy 的值越小越好。</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/24.CrossEntropy.png" alt="Cross Entropy"></p>
<p>而实际上我们会对一大堆data进行training，将每个数据的cross entropy加起来得到一个<code>total loss L</code>，就是如何 minimize 这个 loss L的问题了。</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/25.TotalLoss.png" alt="Total Loss"></p>
<blockquote>
<p>Step 3: pick the best function</p>
</blockquote>
<p>采用 <code>Gradient Descent</code> 方法找到最优，像之前一样计算微分得到gradient向量，然后更新参数，不断反复进行这个process，</p>
<p><img src="/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/26.GradientDescent.png" alt="Gradient Descent - pick the best function"></p>

    </div>


    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------<i class="fa fa-paw"></i>本文结束感谢您的阅读<i class="fa fa-paw"></i>-------------</div>
    
</div>

     
    </div>


    
    
    
        <div class="reward-container">
  <div>请我喝杯奶茶吧～</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="xxx 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.png" alt="xxx 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>xxx
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2021/09/06/Machine-Learning-2021-Spring-(%E4%B8%80)/" title="Machine Learning 2021 Spring (一)">http://example.com/2021/09/06/Machine-Learning-2021-Spring-(一)/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/09/06/Machine-Learning-2021-Spring-Day1/" rel="prev" title="Machine Learning 2021 Spring - Day1">
      <i class="fa fa-chevron-left"></i> Machine Learning 2021 Spring - Day1
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="nav-text">一、机器学习基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Different-types-of-Functions"><span class="nav-text">Different types of Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-Models-%E4%B9%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%89%BE%E5%87%BD%E6%95%B0%E5%BC%8F%E7%9A%84%E8%BF%87%E7%A8%8B-%E2%80%94%E2%80%94-%E4%B8%89%E4%B8%AA%E6%AD%A5%E9%AA%A4"><span class="nav-text">Linear Models 之机器学习找函数式的过程 —— 三个步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#New-Model-More-Features"><span class="nav-text">New Model : More Features</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Back-to-ML-Framework"><span class="nav-text">Back to ML Framework</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-Learning"><span class="nav-text">Deep Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#To-Learn-More-Three-Steps-for-Deep-Learning"><span class="nav-text">To Learn More - Three Steps for Deep Learning</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="xxx"
      src="/images/xin.jpg">
  <p class="site-author-name" itemprop="name">xxx</p>
  <div class="site-description" itemprop="description"> Be happy. </div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xinkjung" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xinkjung" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xinkjung@163.com" title="E-Mail → mailto:xinkjung@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/xinkjung" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;xinkjung" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xxx</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
